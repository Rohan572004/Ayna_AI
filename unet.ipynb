{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21597479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\ml\\envs\\model\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in d:\\ml\\envs\\model\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in d:\\ml\\envs\\model\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\ml\\envs\\model\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\ml\\envs\\model\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\ml\\envs\\model\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ml\\envs\\model\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: wandb in d:\\ml\\envs\\model\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: packaging in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (2.11.7)\n",
      "Requirement already satisfied: pyyaml in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (2.32.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (2.34.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ml\\envs\\model\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\ml\\envs\\model\\lib\\site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\ml\\envs\\model\\lib\\site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\ml\\envs\\model\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ml\\envs\\model\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ml\\envs\\model\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ml\\envs\\model\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.8.3)\n",
      "Requirement already satisfied: colorama in d:\\ml\\envs\\model\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\ml\\envs\\model\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\ml\\envs\\model\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow in d:\\ml\\envs\\model\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: numpy in d:\\ml\\envs\\model\\lib\\site-packages (2.0.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.5-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp310-cp310-win_amd64.whl.metadata (110 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\ml\\envs\\model\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\ml\\envs\\model\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ml\\envs\\model\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Downloading matplotlib-3.10.5-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.8/8.1 MB 9.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.1/8.1 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.2/8.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.8/8.1 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.1/8.1 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 6.6 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.3/2.3 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, opencv-python, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----- ---------------------------------- 1/7 [opencv-python]\n",
      "   ----- ---------------------------------- 1/7 [opencv-python]\n",
      "   ----- ---------------------------------- 1/7 [opencv-python]\n",
      "   ----- ---------------------------------- 1/7 [opencv-python]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ---------------------- ----------------- 4/7 [cycler]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------------- 7/7 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.8 matplotlib-3.10.5 opencv-python-4.12.0.88 pyparsing-3.2.3\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in d:\\ml\\envs\\model\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install wandb\n",
    "!pip install opencv-python pillow numpy matplotlib\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9e5fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 128, 128])\n",
      "Color index: tensor(0)\n",
      "Output shape: torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class PolygonDataset(Dataset):\n",
    "    def __init__(self, root_dir=\"C:/Users/rohan/OneDrive/Desktop/Ayna ML/dataset\", split=\"training\"):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.json_path = os.path.join(self.root_dir, \"data.json\")\n",
    "        with open(self.json_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.RandomAffine(degrees=0, scale=(0.8, 1.2))\n",
    "        ])\n",
    "        self.color_map = {\n",
    "            \"cyan\": 0, \"purple\": 1, \"blue\": 2, \"red\": 3,\n",
    "            \"green\": 4, \"magenta\": 5, \"yellow\": 6, \"orange\": 7\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        input_img_path = os.path.join(self.root_dir, \"inputs\", entry[\"input_polygon\"])\n",
    "        output_img_path = os.path.join(self.root_dir, \"outputs\", entry[\"output_image\"])\n",
    "        input_img = Image.open(input_img_path).convert(\"L\")\n",
    "        output_img = Image.open(output_img_path).convert(\"RGB\")\n",
    "        color = self.color_map[entry[\"colour\"]]\n",
    "        color_tensor = torch.tensor(color, dtype=torch.long)\n",
    "        input_img = self.transform(input_img)\n",
    "        output_img = self.transform(output_img)\n",
    "        return input_img, color_tensor, output_img\n",
    "\n",
    "# Test the dataset\n",
    "dataset = PolygonDataset(\"C:/Users/rohan/OneDrive/Desktop/Ayna ML/dataset\", split=\"training\")\n",
    "input_img, color, output_img = dataset[0]\n",
    "print(\"Input shape:\", input_img.shape)\n",
    "print(\"Color index:\", color)\n",
    "print(\"Output shape:\", output_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ffdf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three entries: [{'input_polygon': 'star.png', 'colour': 'yellow', 'output_image': 'yellow_star.png'}, {'input_polygon': 'triangle.png', 'colour': 'green', 'output_image': 'green_triangle.png'}, {'input_polygon': 'octagon.png', 'colour': 'blue', 'output_image': 'blue_octagon.png'}]\n",
      "Colors in dataset: {'green', 'yellow', 'blue', 'cyan'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_path = 'C:/Users/rohan/OneDrive/Desktop/Ayna ML/dataset/validation/data.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "print(\"First three entries:\", data[:3])\n",
    "colors = set(entry['colour'] for entry in data)\n",
    "print(\"Colors in dataset:\", colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9ac3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML ['dataset', '__MACOSX'] ['checkpoint_1.pth', 'checkpoint_10.pth', 'checkpoint_11.pth', 'checkpoint_12.pth', 'checkpoint_13.pth', 'checkpoint_14.pth', 'checkpoint_15.pth', 'checkpoint_16.pth', 'checkpoint_17.pth', 'checkpoint_18.pth', 'checkpoint_19.pth', 'checkpoint_2.pth', 'checkpoint_20.pth', 'checkpoint_21.pth', 'checkpoint_22.pth', 'checkpoint_23.pth', 'checkpoint_24.pth', 'checkpoint_25.pth', 'checkpoint_26.pth', 'checkpoint_27.pth', 'checkpoint_28.pth', 'checkpoint_29.pth', 'checkpoint_3.pth', 'checkpoint_30.pth', 'checkpoint_31.pth', 'checkpoint_32.pth', 'checkpoint_33.pth', 'checkpoint_34.pth', 'checkpoint_35.pth', 'checkpoint_36.pth', 'checkpoint_37.pth', 'checkpoint_38.pth', 'checkpoint_39.pth', 'checkpoint_4.pth', 'checkpoint_40.pth', 'checkpoint_41.pth', 'checkpoint_42.pth', 'checkpoint_43.pth', 'checkpoint_44.pth', 'checkpoint_45.pth', 'checkpoint_46.pth', 'checkpoint_47.pth', 'checkpoint_48.pth', 'checkpoint_49.pth', 'checkpoint_5.pth', 'checkpoint_50.pth', 'checkpoint_6.pth', 'checkpoint_7.pth', 'checkpoint_8.pth', 'checkpoint_9.pth']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\dataset ['training', 'validation'] ['.DS_Store']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\dataset\\training ['inputs', 'outputs'] ['data.json']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\dataset\\training\\inputs [] ['circle.png', 'diamond.png', 'hexagon.png', 'octagon.png', 'pentagon.png', 'square.png', 'star.png', 'triangle.png']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\dataset\\training\\outputs [] ['blue_circle.png', 'blue_diamond.png', 'blue_hexagon.png', 'blue_octagon.png', 'blue_pentagon.png', 'blue_square.png', 'blue_triangle.png', 'cyan_circle.png', 'cyan_diamond.png', 'cyan_hexagon.png', 'cyan_octagon.png', 'cyan_star.png', 'cyan_triangle.png', 'green_circle.png', 'green_diamond.png', 'green_hexagon.png', 'green_octagon.png', 'green_pentagon.png', 'green_square.png', 'green_star.png', 'magenta_circle.png', 'magenta_diamond.png', 'magenta_hexagon.png', 'magenta_octagon.png', 'magenta_pentagon.png', 'magenta_square.png', 'magenta_triangle.png', 'orange_circle.png', 'orange_diamond.png', 'orange_hexagon.png', 'orange_octagon.png', 'orange_pentagon.png', 'orange_square.png', 'orange_triangle.png', 'purple_circle.png', 'purple_diamond.png', 'purple_hexagon.png', 'purple_octagon.png', 'purple_pentagon.png', 'purple_square.png', 'purple_star.png', 'purple_triangle.png', 'red_circle.png', 'red_diamond.png', 'red_hexagon.png', 'red_octagon.png', 'red_pentagon.png', 'red_square.png', 'red_star.png', 'red_triangle.png', 'yellow_circle.png', 'yellow_diamond.png', 'yellow_hexagon.png', 'yellow_octagon.png', 'yellow_pentagon.png', 'yellow_triangle.png']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\dataset\\validation ['inputs', 'outputs'] ['data.json']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\dataset\\validation\\inputs [] ['octagon.png', 'square.png', 'star.png', 'triangle.png']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\dataset\\validation\\outputs [] ['blue_octagon.png', 'cyan_square.png', 'green_triangle.png', 'yellow_square.png', 'yellow_star.png']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX ['dataset'] []\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset ['wandb'] ['._.DS_Store', 'exp.ipynb', 'unet.ipynb']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb ['run-20250804_190330-oilpycwp', 'run-20250804_190506-z6eh7q61', 'run-20250804_190710-5p8yi83o', 'run-20250804_190945-6xzskku4'] []\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190330-oilpycwp ['files', 'logs', 'tmp'] ['run-oilpycwp.wandb']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190330-oilpycwp\\files [] ['config.yaml', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190330-oilpycwp\\logs [] ['debug-internal.log', 'debug.log']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190330-oilpycwp\\tmp ['code'] []\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190330-oilpycwp\\tmp\\code [] []\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190506-z6eh7q61 ['files', 'logs', 'tmp'] ['run-z6eh7q61.wandb']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190506-z6eh7q61\\files [] ['output.log', 'requirements.txt', 'wandb-metadata.json']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190506-z6eh7q61\\logs [] ['debug-internal.log', 'debug.log']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190506-z6eh7q61\\tmp ['code'] []\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190506-z6eh7q61\\tmp\\code [] []\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190710-5p8yi83o ['files', 'logs', 'tmp'] ['run-5p8yi83o.wandb']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190710-5p8yi83o\\files [] ['config.yaml', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190710-5p8yi83o\\logs [] ['debug-internal.log', 'debug.log']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190710-5p8yi83o\\tmp ['code'] []\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190710-5p8yi83o\\tmp\\code [] []\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190945-6xzskku4 ['files', 'logs', 'tmp'] ['run-6xzskku4.wandb']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190945-6xzskku4\\files [] ['config.yaml', 'output.log', 'requirements.txt', 'wandb-metadata.json', 'wandb-summary.json']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190945-6xzskku4\\logs [] ['debug-internal.log', 'debug.log']\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190945-6xzskku4\\tmp ['code'] []\n",
      "C:/Users/rohan/OneDrive/Desktop/Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_190945-6xzskku4\\tmp\\code [] []\n"
     ]
    }
   ],
   "source": [
    "# checking the local dataset structure\n",
    "import os\n",
    "for root, dirs, files in os.walk(\"C:/Users/rohan/OneDrive/Desktop/Ayna ML\"):\n",
    "    print(root, dirs, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f875c824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 128, 128])\n",
      "Color index: tensor(0)\n",
      "Output shape: torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class PolygonDataset(Dataset):\n",
    "    def __init__(self, root_dir=\"C:/Users/rohan/OneDrive/Desktop/Ayna ML/dataset\", split=\"training\"):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.json_path = os.path.join(self.root_dir, \"data.json\")\n",
    "        with open(self.json_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.RandomAffine(degrees=0, scale=(0.8, 1.2))\n",
    "        ])\n",
    "        self.color_map = {\n",
    "            \"cyan\": 0, \"purple\": 1, \"blue\": 2, \"red\": 3,\n",
    "            \"green\": 4, \"magenta\": 5, \"yellow\": 6, \"orange\": 7\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        input_img_path = os.path.join(self.root_dir, \"inputs\", entry[\"input_polygon\"])\n",
    "        output_img_path = os.path.join(self.root_dir, \"outputs\", entry[\"output_image\"])\n",
    "        input_img = Image.open(input_img_path).convert(\"L\")\n",
    "        output_img = Image.open(output_img_path).convert(\"RGB\")\n",
    "        color = self.color_map[entry[\"colour\"]]\n",
    "        color_tensor = torch.tensor(color, dtype=torch.long)\n",
    "        input_img = self.transform(input_img)\n",
    "        output_img = self.transform(output_img)\n",
    "        return input_img, color_tensor, output_img\n",
    "\n",
    "# Test the dataset\n",
    "dataset = PolygonDataset(\"C:/Users/rohan/OneDrive/Desktop/Ayna ML/dataset\", split=\"training\")\n",
    "input_img, color, output_img = dataset[0]\n",
    "print(\"Input shape:\", input_img.shape)\n",
    "print(\"Color index:\", color)\n",
    "print(\"Output shape:\", output_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08203ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: wandb 0.21.0\n",
      "Uninstalling wandb-0.21.0:\n",
      "  Successfully uninstalled wandb-0.21.0\n",
      "Collecting wandb\n",
      "  Using cached wandb-0.21.0-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: packaging in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (2.11.7)\n",
      "Requirement already satisfied: pyyaml in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (2.32.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (2.34.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in d:\\ml\\envs\\model\\lib\\site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ml\\envs\\model\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\ml\\envs\\model\\lib\\site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\ml\\envs\\model\\lib\\site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\ml\\envs\\model\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ml\\envs\\model\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ml\\envs\\model\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ml\\envs\\model\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.8.3)\n",
      "Requirement already satisfied: colorama in d:\\ml\\envs\\model\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\ml\\envs\\model\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\ml\\envs\\model\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Using cached wandb-0.21.0-py3-none-win_amd64.whl (21.5 MB)\n",
      "Installing collected packages: wandb\n",
      "Successfully installed wandb-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall wandb -y\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4c00a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\rohan\\_netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrohankanthale0\u001b[0m (\u001b[33mrohankanthale0-bharati-vidyapeeth\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "print(wandb.__version__)\n",
    "wandb.login(key=\"62ec231cf8dc001f9896900c9e1b60ba5571b11f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e795000b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checkpoint_1.pth', 'checkpoint_10.pth', 'checkpoint_11.pth', 'checkpoint_12.pth', 'checkpoint_13.pth', 'checkpoint_14.pth', 'checkpoint_15.pth', 'checkpoint_16.pth', 'checkpoint_17.pth', 'checkpoint_18.pth', 'checkpoint_19.pth', 'checkpoint_2.pth', 'checkpoint_20.pth', 'checkpoint_21.pth', 'checkpoint_22.pth', 'checkpoint_23.pth', 'checkpoint_24.pth', 'checkpoint_25.pth', 'checkpoint_26.pth', 'checkpoint_27.pth', 'checkpoint_28.pth', 'checkpoint_29.pth', 'checkpoint_3.pth', 'checkpoint_30.pth', 'checkpoint_31.pth', 'checkpoint_32.pth', 'checkpoint_33.pth', 'checkpoint_34.pth', 'checkpoint_35.pth', 'checkpoint_36.pth', 'checkpoint_37.pth', 'checkpoint_38.pth', 'checkpoint_39.pth', 'checkpoint_4.pth', 'checkpoint_40.pth', 'checkpoint_41.pth', 'checkpoint_42.pth', 'checkpoint_43.pth', 'checkpoint_44.pth', 'checkpoint_45.pth', 'checkpoint_46.pth', 'checkpoint_47.pth', 'checkpoint_48.pth', 'checkpoint_49.pth', 'checkpoint_5.pth', 'checkpoint_50.pth', 'checkpoint_6.pth', 'checkpoint_7.pth', 'checkpoint_8.pth', 'checkpoint_9.pth', 'dataset', '__MACOSX']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"C:/Users/rohan/OneDrive/Desktop/Ayna ML\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4821ea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\rohan\\_netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter notebook - using default configuration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\rohan\\OneDrive\\Desktop\\Ayna ML\\__MACOSX\\dataset\\wandb\\run-20250804_215214-w1bqzjxb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved/runs/w1bqzjxb' target=\"_blank\">unet_lr0.0005_bs8</a></strong> to <a href='https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved' target=\"_blank\">https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved/runs/w1bqzjxb' target=\"_blank\">https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved/runs/w1bqzjxb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 56\n",
      "Validation samples: 5\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "GPU Memory: 6.4 GB\n",
      "Total parameters: 31,318,595\n",
      "Trainable parameters: 31,318,595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  5.52it/s, loss=0.3340, avg_loss=0.3553]\n",
      "Epoch 1/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 34.24it/s, val_loss=0.2436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.3553, Val Loss: 0.2436, LR: 5.00e-04\n",
      "New best model saved with validation loss: 0.2436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.66it/s, loss=0.2728, avg_loss=0.3057]\n",
      "Epoch 2/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 32.46it/s, val_loss=0.4165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.3057, Val Loss: 0.4165, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.60it/s, loss=0.2936, avg_loss=0.2984]\n",
      "Epoch 3/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 31.27it/s, val_loss=0.2044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.2984, Val Loss: 0.2044, LR: 5.00e-04\n",
      "New best model saved with validation loss: 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.58it/s, loss=0.2922, avg_loss=0.3014]\n",
      "Epoch 4/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.88it/s, val_loss=0.1603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.3014, Val Loss: 0.1603, LR: 5.00e-04\n",
      "New best model saved with validation loss: 0.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.55it/s, loss=0.3166, avg_loss=0.2880]\n",
      "Epoch 5/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.87it/s, val_loss=0.1941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.2880, Val Loss: 0.1941, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.61it/s, loss=0.2632, avg_loss=0.2864]\n",
      "Epoch 6/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 32.88it/s, val_loss=0.1700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.2864, Val Loss: 0.1700, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.39it/s, loss=0.2714, avg_loss=0.2684]\n",
      "Epoch 7/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 32.60it/s, val_loss=0.1728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.2684, Val Loss: 0.1728, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.49it/s, loss=0.2499, avg_loss=0.2223]\n",
      "Epoch 8/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.10it/s, val_loss=0.2821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.2223, Val Loss: 0.2821, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.42it/s, loss=0.2395, avg_loss=0.2554]\n",
      "Epoch 9/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.77it/s, val_loss=0.2390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.2554, Val Loss: 0.2390, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.33it/s, loss=0.2567, avg_loss=0.2203]\n",
      "Epoch 10/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.68it/s, val_loss=0.1780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.2203, Val Loss: 0.1780, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.59it/s, loss=0.2168, avg_loss=0.2322]\n",
      "Epoch 11/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 35.30it/s, val_loss=0.1627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.2322, Val Loss: 0.1627, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.60it/s, loss=0.1915, avg_loss=0.2218]\n",
      "Epoch 12/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.49it/s, val_loss=0.1477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.2218, Val Loss: 0.1477, LR: 5.00e-04\n",
      "New best model saved with validation loss: 0.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.56it/s, loss=0.2006, avg_loss=0.2204]\n",
      "Epoch 13/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 34.73it/s, val_loss=0.1600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.2204, Val Loss: 0.1600, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.57it/s, loss=0.2624, avg_loss=0.2175]\n",
      "Epoch 14/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 32.68it/s, val_loss=0.1645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.2175, Val Loss: 0.1645, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.56it/s, loss=0.2383, avg_loss=0.2231]\n",
      "Epoch 15/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 34.43it/s, val_loss=0.1469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.2231, Val Loss: 0.1469, LR: 5.00e-04\n",
      "New best model saved with validation loss: 0.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.37it/s, loss=0.2358, avg_loss=0.2136]\n",
      "Epoch 16/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 34.02it/s, val_loss=0.1687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss: 0.2136, Val Loss: 0.1687, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.56it/s, loss=0.2576, avg_loss=0.2039]\n",
      "Epoch 17/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 32.78it/s, val_loss=0.1701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss: 0.2039, Val Loss: 0.1701, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.54it/s, loss=0.2275, avg_loss=0.2147]\n",
      "Epoch 18/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.37it/s, val_loss=0.1673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss: 0.2147, Val Loss: 0.1673, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.55it/s, loss=0.2172, avg_loss=0.2300]\n",
      "Epoch 19/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 34.54it/s, val_loss=0.1766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss: 0.2300, Val Loss: 0.1766, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.57it/s, loss=0.2084, avg_loss=0.2041]\n",
      "Epoch 20/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.77it/s, val_loss=0.1786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss: 0.2041, Val Loss: 0.1786, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.58it/s, loss=0.1975, avg_loss=0.2260]\n",
      "Epoch 21/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.67it/s, val_loss=0.1572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss: 0.2260, Val Loss: 0.1572, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.50it/s, loss=0.2339, avg_loss=0.2164]\n",
      "Epoch 22/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.27it/s, val_loss=0.1715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss: 0.2164, Val Loss: 0.1715, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.53it/s, loss=0.2009, avg_loss=0.2071]\n",
      "Epoch 23/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 32.46it/s, val_loss=0.1740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss: 0.2071, Val Loss: 0.1740, LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.62it/s, loss=0.1756, avg_loss=0.2124]\n",
      "Epoch 24/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 34.98it/s, val_loss=0.1790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss: 0.2124, Val Loss: 0.1790, LR: 3.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.55it/s, loss=0.2545, avg_loss=0.2210]\n",
      "Epoch 25/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 33.78it/s, val_loss=0.1833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss: 0.2210, Val Loss: 0.1833, LR: 3.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.49it/s, loss=0.1784, avg_loss=0.2052]\n",
      "Epoch 26/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 35.15it/s, val_loss=0.1911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss: 0.2052, Val Loss: 0.1911, LR: 3.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 [Train]: 100%|██████████| 7/7 [00:01<00:00,  6.67it/s, loss=0.1853, avg_loss=0.1971]\n",
      "Epoch 27/100 [Val]: 100%|██████████| 1/1 [00:00<00:00, 32.83it/s, val_loss=0.1850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss: 0.1971, Val Loss: 0.1850, LR: 3.50e-04\n",
      "Early stopping triggered at epoch 27\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>learning_rate</td><td>███████████████████████▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▆▅▅▄▂▄▂▃▂▂▂▂▂▁▂▂▁▂▂▁▂▂▁▁</td></tr><tr><td>val_loss</td><td>▄█▂▁▂▂▂▅▃▂▁▁▁▁▁▂▂▂▂▂▁▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>27</td></tr><tr><td>learning_rate</td><td>0.00035</td></tr><tr><td>train_loss</td><td>0.19709</td></tr><tr><td>val_loss</td><td>0.18503</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet_lr0.0005_bs8</strong> at: <a href='https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved/runs/w1bqzjxb' target=\"_blank\">https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved/runs/w1bqzjxb</a><br> View project at: <a href='https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved' target=\"_blank\">https://wandb.ai/rohankanthale0-bharati-vidyapeeth/ayna_unet_improved</a><br>Synced 5 W&B file(s), 6 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250804_215214-w1bqzjxb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import wandb first and log in\n",
    "import wandb\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset  # Added Dataset import\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# Other imports\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration class for better parameter management\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Training parameters\n",
    "        self.learning_rate = 5e-4  # Reduced learning rate\n",
    "        self.epochs = 100  # More epochs for small dataset\n",
    "        self.batch_size = 8   # Smaller batch size for small dataset\n",
    "        self.num_workers = 0  # Set to 0 for Windows compatibility\n",
    "        self.pin_memory = False  # Disable for stability on some systems\n",
    "        \n",
    "        # Model parameters\n",
    "        self.in_channels = 1\n",
    "        self.out_channels = 3\n",
    "        self.num_colors = 8\n",
    "        \n",
    "        # Paths\n",
    "        self.dataset_root = \"C:/Users/rohan/OneDrive/Desktop/Ayna ML/dataset\"\n",
    "        self.checkpoint_dir = \"C:/Users/rohan/OneDrive/Desktop/Ayna ML/checkpoints\"\n",
    "        self.wandb_project = \"ayna_unet_improved\"\n",
    "        \n",
    "        # Training settings\n",
    "        self.early_stopping_patience = 15  # More patience for small dataset\n",
    "        self.save_every_n_epochs = 10\n",
    "        self.validate_every_n_epochs = 1\n",
    "        \n",
    "        # Scheduler settings\n",
    "        self.scheduler_patience = 8  # More patience\n",
    "        self.scheduler_factor = 0.7  # Less aggressive reduction\n",
    "        self.min_lr = 1e-8\n",
    "\n",
    "# Enhanced Dataset with better error handling and augmentations\n",
    "class PolygonDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, split: str = \"training\", augment: bool = True):\n",
    "        self.root_dir = Path(root_dir) / split\n",
    "        self.json_path = self.root_dir / \"data.json\"\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Load and validate data\n",
    "        try:\n",
    "            with open(self.json_path, 'r') as f:\n",
    "                self.data = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Data file not found: {self.json_path}\")\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(f\"Invalid JSON file: {self.json_path}\")\n",
    "        \n",
    "        # Color mapping\n",
    "        self.color_map = {\n",
    "            \"cyan\": 0, \"purple\": 1, \"blue\": 2, \"red\": 3,\n",
    "            \"green\": 4, \"magenta\": 5, \"yellow\": 6, \"orange\": 7\n",
    "        }\n",
    "        \n",
    "        # Define transforms\n",
    "        self.base_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((128, 128), antialias=True)\n",
    "        ])\n",
    "        \n",
    "        self.augment_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((128, 128), antialias=True),\n",
    "            transforms.RandomRotation(45),  # More aggressive rotation\n",
    "            transforms.RandomAffine(degrees=0, scale=(0.7, 1.3), translate=(0.1, 0.1)),  # More augmentation\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.3),  # Add vertical flip\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3) if split == \"training\" else transforms.Lambda(lambda x: x)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        \n",
    "        try:\n",
    "            # Load images\n",
    "            input_img_path = self.root_dir / \"inputs\" / entry[\"input_polygon\"]\n",
    "            output_img_path = self.root_dir / \"outputs\" / entry[\"output_image\"]\n",
    "            \n",
    "            input_img = Image.open(input_img_path).convert(\"L\")\n",
    "            output_img = Image.open(output_img_path).convert(\"RGB\")\n",
    "            \n",
    "            # Get color encoding\n",
    "            color = self.color_map.get(entry[\"colour\"])\n",
    "            if color is None:\n",
    "                raise ValueError(f\"Unknown color: {entry['colour']}\")\n",
    "            \n",
    "            color_tensor = torch.tensor(color, dtype=torch.long)\n",
    "            \n",
    "            \n",
    "            transform = self.augment_transform if self.augment else self.base_transform\n",
    "            input_img = transform(input_img)\n",
    "            output_img = transform(output_img)\n",
    "            \n",
    "            return input_img, color_tensor, output_img\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx}: {e}\")\n",
    "            # Return a dummy sample in case of error\n",
    "            return torch.zeros(1, 128, 128), torch.tensor(0, dtype=torch.long), torch.zeros(3, 128, 128)\n",
    "\n",
    "# Improved UNet with better architecture\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 8, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 8, in_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attention_weights = self.attention(x)\n",
    "        return x * attention_weights\n",
    "\n",
    "class ImprovedUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, num_colors=8, dropout_rate=0.1):\n",
    "        super(ImprovedUNet, self).__init__()\n",
    "        self.num_colors = num_colors\n",
    "        \n",
    "        # Color embedding with better dimension\n",
    "        self.color_embedding = nn.Embedding(num_colors, 32)\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = DoubleConv(in_channels + 32, 64, dropout_rate)\n",
    "        self.enc2 = DoubleConv(64, 128, dropout_rate)\n",
    "        self.enc3 = DoubleConv(128, 256, dropout_rate)\n",
    "        self.enc4 = DoubleConv(256, 512, dropout_rate)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck with attention\n",
    "        self.bottleneck = DoubleConv(512, 1024, dropout_rate)\n",
    "        self.attention = AttentionBlock(1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.dec4 = DoubleConv(1024, 512, dropout_rate)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(512, 256, dropout_rate)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(256, 128, dropout_rate)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(128, 64, dropout_rate)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(64, out_channels, 1),\n",
    "            nn.Sigmoid()  # Ensure output is in [0, 1] range\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x, color):\n",
    "        # Embed color information\n",
    "        batch_size, _, height, width = x.shape\n",
    "        color_embed = self.color_embedding(color)\n",
    "        color_embed = color_embed.view(batch_size, -1, 1, 1)\n",
    "        color_embed = color_embed.expand(-1, -1, height, width)\n",
    "        \n",
    "        # Concatenate input with color embedding\n",
    "        x = torch.cat([x, color_embed], dim=1)\n",
    "        \n",
    "        # Encoder path\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        \n",
    "        # Bottleneck with attention\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        b = self.attention(b)\n",
    "        \n",
    "        # Decoder path\n",
    "        d4 = self.up4(b)\n",
    "        d4 = self.dec4(torch.cat([d4, e4], dim=1))\n",
    "        \n",
    "        d3 = self.up3(d4)\n",
    "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
    "        \n",
    "        d1 = self.up1(d2)\n",
    "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
    "        \n",
    "        return self.out(d1)\n",
    "\n",
    "# Enhanced loss functions\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, mse_weight=1.0, l1_weight=0.1, perceptual_weight=0.1):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.mse_weight = mse_weight\n",
    "        self.l1_weight = l1_weight\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        mse = self.mse_loss(pred, target)\n",
    "        l1 = self.l1_loss(pred, target)\n",
    "        return self.mse_weight * mse + self.l1_weight * l1\n",
    "\n",
    "# Training utilities\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, loss, filepath):\n",
    "    \"\"\"Save model checkpoint\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "\n",
    "def load_checkpoint(filepath, model, optimizer=None, scheduler=None):\n",
    "    \"\"\"Load model checkpoint\"\"\"\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if scheduler:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    return checkpoint['epoch'], checkpoint['loss']\n",
    "\n",
    "def visualize_predictions(model, dataloader, device, num_samples=4):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (input_img, color, target) in enumerate(dataloader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            input_img = input_img.to(device)\n",
    "            color = color.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            pred = model(input_img, color)\n",
    "            \n",
    "            # Create visualization grid\n",
    "            grid_input = make_grid(input_img[:4], nrow=4, normalize=True)\n",
    "            grid_target = make_grid(target[:4], nrow=4, normalize=True)\n",
    "            grid_pred = make_grid(pred[:4], nrow=4, normalize=True)\n",
    "            \n",
    "            # Log to wandb\n",
    "            wandb.log({\n",
    "                f\"input_batch_{i}\": wandb.Image(grid_input),\n",
    "                f\"target_batch_{i}\": wandb.Image(grid_target),\n",
    "                f\"prediction_batch_{i}\": wandb.Image(grid_pred)\n",
    "            })\n",
    "\n",
    "# Main training function\n",
    "def train_model(config: Config, wandb_key: Optional[str] = None):\n",
    "    # Login to wandb if key provided\n",
    "    if wandb_key:\n",
    "        wandb.login(key=wandb_key)\n",
    "    \n",
    "    # Initialize wandb\n",
    "    wandb.init(\n",
    "        project=config.wandb_project,\n",
    "        config=vars(config),\n",
    "        name=f\"unet_lr{config.learning_rate}_bs{config.batch_size}\"\n",
    "    )\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    Path(config.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Setup datasets\n",
    "    try:\n",
    "        train_dataset = PolygonDataset(config.dataset_root, split=\"training\", augment=True)\n",
    "        val_dataset = PolygonDataset(config.dataset_root, split=\"validation\", augment=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading datasets: {e}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Setup data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Force to 0 for Windows compatibility\n",
    "        pin_memory=False,  # Disable for stability\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=0,  # Force to 0 for Windows compatibility\n",
    "        pin_memory=False  # Disable for stability\n",
    "    )\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ImprovedUNet(\n",
    "        in_channels=config.in_channels,\n",
    "        out_channels=config.out_channels,\n",
    "        num_colors=config.num_colors\n",
    "    ).to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Setup loss, optimizer, and scheduler\n",
    "    criterion = CombinedLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=config.learning_rate, weight_decay=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        patience=config.scheduler_patience, \n",
    "        factor=config.scheduler_factor,\n",
    "        min_lr=config.min_lr,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=config.early_stopping_patience)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epochs} [Train]\")\n",
    "        \n",
    "        for batch_idx, (input_img, color, output_img) in enumerate(train_pbar):\n",
    "            input_img = input_img.to(device, non_blocking=True)\n",
    "            color = color.to(device, non_blocking=True)\n",
    "            output_img = output_img.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(input_img, color)\n",
    "            loss = criterion(pred, output_img)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'avg_loss': f'{train_loss/(batch_idx+1):.4f}'\n",
    "            })\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        if (epoch + 1) % config.validate_every_n_epochs == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config.epochs} [Val]\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for input_img, color, output_img in val_pbar:\n",
    "                    input_img = input_img.to(device, non_blocking=True)\n",
    "                    color = color.to(device, non_blocking=True)\n",
    "                    output_img = output_img.to(device, non_blocking=True)\n",
    "                    \n",
    "                    pred = model(input_img, color)\n",
    "                    loss = criterion(pred, output_img)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    val_pbar.set_postfix({'val_loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Log metrics\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"learning_rate\": current_lr\n",
    "            })\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {current_lr:.2e}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                save_checkpoint(\n",
    "                    model, optimizer, scheduler, epoch + 1, val_loss,\n",
    "                    Path(config.checkpoint_dir) / \"best_model.pth\"\n",
    "                )\n",
    "                print(f\"New best model saved with validation loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # Visualize predictions periodically\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                visualize_predictions(model, val_loader, device)\n",
    "            \n",
    "            # Early stopping check\n",
    "            if early_stopping(val_loss):\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        # Save checkpoint periodically\n",
    "        if (epoch + 1) % config.save_every_n_epochs == 0:\n",
    "            save_checkpoint(\n",
    "                model, optimizer, scheduler, epoch + 1, train_loss,\n",
    "                Path(config.checkpoint_dir) / f\"checkpoint_epoch_{epoch+1}.pth\"\n",
    "            )\n",
    "    \n",
    "    # Save final model\n",
    "    save_checkpoint(\n",
    "        model, optimizer, scheduler, epoch + 1, val_loss if 'val_loss' in locals() else train_loss,\n",
    "        Path(config.checkpoint_dir) / \"final_model.pth\"\n",
    "    )\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    wandb.finish()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    # Check if running in Jupyter notebook\n",
    "    if any('ipykernel' in arg for arg in sys.argv):\n",
    "        # Running in Jupyter - use default configuration\n",
    "        print(\"Running in Jupyter notebook - using default configuration\")\n",
    "        config = Config()\n",
    "        \n",
    "        # Train the model\n",
    "        try:\n",
    "            train_model(config, wandb_key=\"62ec231cf8dc001f9896900c9e1b60ba5571b11f\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Training interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"Training failed with error: {e}\")\n",
    "            raise\n",
    "    else:\n",
    "        # Running from command line - parse arguments\n",
    "        parser = argparse.ArgumentParser(description='Train UNet for polygon coloring')\n",
    "        parser.add_argument('--config', type=str, help='Path to config file')\n",
    "        parser.add_argument('--wandb_key', type=str, help='Weights & Biases API key')\n",
    "        parser.add_argument('--resume', type=str, help='Path to checkpoint to resume from')\n",
    "        \n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        # Initialize configuration\n",
    "        config = Config()\n",
    "        \n",
    "        # Override config with command line arguments if provided\n",
    "        wandb_key = args.wandb_key if args.wandb_key else \"62ec231cf8dc001f9896900c9e1b60ba5571b11f\"\n",
    "        \n",
    "        # Train the model\n",
    "        try:\n",
    "            train_model(config, wandb_key=wandb_key)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Training interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"Training failed with error: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78c0d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in d:\\ml\\envs\\detect\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in d:\\ml\\envs\\detect\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in d:\\ml\\envs\\detect\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in d:\\ml\\envs\\detect\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\ml\\envs\\detect\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\ml\\envs\\detect\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\ml\\envs\\detect\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\ml\\envs\\detect\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\ml\\envs\\detect\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in d:\\ml\\envs\\detect\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in d:\\ml\\envs\\detect\\lib\\site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\ml\\envs\\detect\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\ml\\envs\\detect\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ml\\envs\\detect\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af171db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Using device: cuda\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import MSELoss\n",
    "import os\n",
    "\n",
    "# GPU Setup Check\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Force GPU usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Your training setup with GPU\n",
    "model = nn.Linear(10, 1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = MSELoss()\n",
    "\n",
    "# Ensure model is on GPU\n",
    "print(\"Model device:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f29a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbformat\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: torch in d:\\ml\\envs\\model\\lib\\site-packages (2.5.1)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat)\n",
      "  Using cached fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat)\n",
      "  Using cached jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\ml\\envs\\model\\lib\\site-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in d:\\ml\\envs\\model\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: filelock in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\ml\\envs\\model\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\ml\\envs\\model\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat)\n",
      "  Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\ml\\envs\\model\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\ml\\envs\\model\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (311)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ml\\envs\\model\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.1/6.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 6.7 MB/s eta 0:00:00\n",
      "Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Using cached jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl (231 kB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: fastjsonschema, sympy, rpds-py, fsspec, attrs, referencing, jsonschema-specifications, jsonschema, nbformat\n",
      "\n",
      "  Attempting uninstall: sympy\n",
      "\n",
      "    Found existing installation: sympy 1.13.3\n",
      "\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "    Uninstalling sympy-1.13.3:\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ---- ----------------------------------- 1/9 [sympy]\n",
      "   ------------- -------------------------- 3/9 [fsspec]\n",
      "   ------------- -------------------------- 3/9 [fsspec]\n",
      "   ------------- -------------------------- 3/9 [fsspec]\n",
      "   ------------- -------------------------- 3/9 [fsspec]\n",
      "   ----------------- ---------------------- 4/9 [attrs]\n",
      "   ----------------- ---------------------- 4/9 [attrs]\n",
      "   ---------------------- ----------------- 5/9 [referencing]\n",
      "   ------------------------------- -------- 7/9 [jsonschema]\n",
      "   ------------------------------- -------- 7/9 [jsonschema]\n",
      "   ------------------------------- -------- 7/9 [jsonschema]\n",
      "   ----------------------------------- ---- 8/9 [nbformat]\n",
      "   ----------------------------------- ---- 8/9 [nbformat]\n",
      "   ----------------------------------- ---- 8/9 [nbformat]\n",
      "   ---------------------------------------- 9/9 [nbformat]\n",
      "\n",
      "Successfully installed attrs-25.3.0 fastjsonschema-2.21.1 fsspec-2025.7.0 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 nbformat-5.10.4 referencing-0.36.2 rpds-py-0.26.0 sympy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nbformat torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
